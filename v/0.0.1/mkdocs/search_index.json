{
    "docs": [
        {
            "location": "/index.html",
            "text": "OpenEO - Core API Concepts and Reference\n\n\nThe OpenEO core API defines a RESTful API that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete API reference documentation. As an overview, the OpenEO API specifies how to\n\n\n\n\ndiscover which Earth observation data and processes are available at cloud back-ends,\n\n\nexecute (chained) processes on back-ends, \n\n\nrun user-defined functions (UDFs) on back-ends where UDFs can be exposed to the data in different ways, \n\n\ndownload (intermediate) results as web services, and\n\n\nmanage user content including accounting.\n\n\n\n\nThe API is defined as an \nOpenAPI 3.0.0\n JSON file. To simplify and structure the development, the API is divided into a few \nmicroservices\n.\n\n\n\n\nOpenEO\n, A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020.",
            "title": "Home"
        },
        {
            "location": "/index.html#openeo-core-api-concepts-and-reference",
            "text": "The OpenEO core API defines a RESTful API that lets cloud back-ends with large Earth observation datasets communicate with front end analysis applications in an interoperable way. This documentation describes important API concepts and design decisions and gives a complete API reference documentation. As an overview, the OpenEO API specifies how to   discover which Earth observation data and processes are available at cloud back-ends,  execute (chained) processes on back-ends,   run user-defined functions (UDFs) on back-ends where UDFs can be exposed to the data in different ways,   download (intermediate) results as web services, and  manage user content including accounting.   The API is defined as an  OpenAPI 3.0.0  JSON file. To simplify and structure the development, the API is divided into a few  microservices .   OpenEO , A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H2020 project funded under call EO-2-2017: EO Big Data Shift, under proposal number 776242. It will run from Oct 2017 to Sept 2020.",
            "title": "OpenEO - Core API Concepts and Reference"
        },
        {
            "location": "/arch/index.html",
            "text": "Architecture\n\n\nThe OpenEO core API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below.\n\n\n\n\nThe OpenEO core API is a contract betewen clients and backends that describes the communication only\n\n\nEach back-end runs its own API instance including the specific back-end driver. There is no core API instance that runs more than one driver.\n\n\nClients in R, Python, and JavaScript connect directly to the backends and communicate with the backends over HTTP(s) acoording to the OpenEO core API specification.\n\n\nAPI instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way.\n\n\nBack-ends may add functionality and extend the core API wherever there is need.\n\n\nThere will be a central backend registry service, to allow users to search for backends with specific functionality and or data. \n\n\nThe OpenEO core API will define \nprofiles\n in order group specific functionality.\n\n\n\n\n\n\nMicroservices\n\n\n\n\n\n\n\n\nMicroservice\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAPI Information\n\n\nThis microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end.\n\n\n\n\n\n\nData Discovery\n\n\nDescribes which datasets and image collections are available at the backend.\n\n\n\n\n\n\nProcess Discovery\n\n\nProvides services to find out which processes a back-end provides, i.e., what users can do with the available data.\n\n\n\n\n\n\nJob Management\n\n\nOrganizes and manages jobs that run processes on back-ends\n\n\n\n\n\n\nDownload\n\n\nServices to download data and job results e.g. as WCS or WMTS service.\n\n\n\n\n\n\nUser Data Management\n\n\nManage user content and accounting, all",
            "title": "Architecture and Microservices"
        },
        {
            "location": "/arch/index.html#architecture",
            "text": "The OpenEO core API defines a language how clients communicate to back-ends in order to analyze large Earth observation datasets. The API will be implemented by drivers for specific back-ends. Some first architecture considerations are listed below.   The OpenEO core API is a contract betewen clients and backends that describes the communication only  Each back-end runs its own API instance including the specific back-end driver. There is no core API instance that runs more than one driver.  Clients in R, Python, and JavaScript connect directly to the backends and communicate with the backends over HTTP(s) acoording to the OpenEO core API specification.  API instances can run on back-end servers or additional intermediate layers, which then communicate to back-ends in a back-end specific way.  Back-ends may add functionality and extend the core API wherever there is need.  There will be a central backend registry service, to allow users to search for backends with specific functionality and or data.   The OpenEO core API will define  profiles  in order group specific functionality.",
            "title": "Architecture"
        },
        {
            "location": "/arch/index.html#microservices",
            "text": "Microservice  Description      API Information  This microservice reports on the capabilities of the back-end, i.e. which API endpoints are implemented, which authentication methods are supported, and whether and how UDFs can be executed at the back-end.    Data Discovery  Describes which datasets and image collections are available at the backend.    Process Discovery  Provides services to find out which processes a back-end provides, i.e., what users can do with the available data.    Job Management  Organizes and manages jobs that run processes on back-ends    Download  Services to download data and job results e.g. as WCS or WMTS service.    User Data Management  Manage user content and accounting, all",
            "title": "Microservices"
        },
        {
            "location": "/jobs/index.html",
            "text": "Processes, Tasks, Jobs\n\n\nThe terms \nprocess\n, \ntask\n, and \njob\n have different meanings in the OpenEO API specification.\n\n\nA \nprocess\n is simply the description of an operation as provided by the back end, similar to a function definition in programming languages. \n\n\nA \ntask\n includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, tasks can chain multiple processes. In particular, arguments of processes in general can be again (recursive) tasks, input datasets, or simple scalar or array values.\n\n\nA \njob\n brings one task to the back-end and organizes its execution, which may or may not induce costs. Jobs furthermore allow to run tasks from different \ndata views\n (see section on \ndata views\n). Views define at which resolution and extent we look at the data during processing and hence allow to try out tasks on small subsets, or work interactively within web map applications.\n\n\nJob Evaluation\n\n\nThe API distinguishes two types how jobs are executed at back-ends. \nLazy evaluation\n runs computations on demand, i.e., with incoming requests for downloading the results. Jobs can be executed multiple times with different views (including spatial / temporal resolution and window) as provided by download requests, which could come e.g. from WCS or WMTS.  \nBatch jobs\n in contrast are directly submitted to the back office's processing system. They will run only once, potentially include a provided view, and will store results after execution. Batch jobs are typically time consuming such that user interaction is not possible. \n\n\nAs an example we consider the simple calculation of vegetation indexes on all available Sentinel 2 imagery over Europe. Batch evaluation will take all relevant images, compute the NDVI, and finally store the result whereas lazy evaluation will not start any computations on its own. As soon as a client performs a download request such as a \nGetCoverage\n WCS request, the job's process will be executed but only for requested pixels. However, back-ends are free to cache frequent intermediate results on their own.",
            "title": "Jobs"
        },
        {
            "location": "/jobs/index.html#processes-tasks-jobs",
            "text": "The terms  process ,  task , and  job  have different meanings in the OpenEO API specification.  A  process  is simply the description of an operation as provided by the back end, similar to a function definition in programming languages.   A  task  includes specific process calls, i.e. references to one or more processes including specific values for input arguments similar to a function call in programming. However, tasks can chain multiple processes. In particular, arguments of processes in general can be again (recursive) tasks, input datasets, or simple scalar or array values.  A  job  brings one task to the back-end and organizes its execution, which may or may not induce costs. Jobs furthermore allow to run tasks from different  data views  (see section on  data views ). Views define at which resolution and extent we look at the data during processing and hence allow to try out tasks on small subsets, or work interactively within web map applications.",
            "title": "Processes, Tasks, Jobs"
        },
        {
            "location": "/jobs/index.html#job-evaluation",
            "text": "The API distinguishes two types how jobs are executed at back-ends.  Lazy evaluation  runs computations on demand, i.e., with incoming requests for downloading the results. Jobs can be executed multiple times with different views (including spatial / temporal resolution and window) as provided by download requests, which could come e.g. from WCS or WMTS.   Batch jobs  in contrast are directly submitted to the back office's processing system. They will run only once, potentially include a provided view, and will store results after execution. Batch jobs are typically time consuming such that user interaction is not possible.   As an example we consider the simple calculation of vegetation indexes on all available Sentinel 2 imagery over Europe. Batch evaluation will take all relevant images, compute the NDVI, and finally store the result whereas lazy evaluation will not start any computations on its own. As soon as a client performs a download request such as a  GetCoverage  WCS request, the job's process will be executed but only for requested pixels. However, back-ends are free to cache frequent intermediate results on their own.",
            "title": "Job Evaluation"
        },
        {
            "location": "/udfs/index.html",
            "text": "UDFs\n\n\nUser-defined functions (UDFs) can be exposed to the data in different ways. This includes which parts of the\ndata are passed to the function, how the function execution is parallelized, and how the expected output is structured. The OpenEO core API defines the following UDF types:\n\n\n\n\napply_pixel\n\n\napply_scene\n\n\nreduce_time\n\n\nreduce_space\n\n\nwindow_time\n\n\nwindow_space\n\n\nwindow_spacetime\n\n\naggregate_time\n\n\naggregate_space\n\n\naggregate_spacetime\n\n\nchunkreduce_time\n\n\nchunkreduce_space\n\n\nchunkreduce_spacetime\n\n\n\n\nThis document describes some details of the abovementioned UDF types. Back-ends allowing the execution of UDF's will report, which types they support. For example applying UDFs on individual scenes is not possible on higher level data cube back-ends. In the descriptions below, the question in which format data is streamed to and from the functions is not yet covered. Furthermore, the described categories only include unary operations that take one image (collection) as input.  \n\n\nUDF types\n\n\napply_pixel\n\n\nThis type applies a simple function to one pixel of the input image or image collection. The function gets the value of one pixel (including all bands) as input and produces a single scalar or tuple output. The result has the same schema as the input image (collection) but different bands. Examples include the computation of vegetation indexes or filtering cloudy pixels. \n\n\napply_scene\n\n\nThis low-level UDF type applies a function on individual scenes.  The function gets a single scene as input and produces a modified \"scene\" with the same spatial footprint. This UDF type will only be supported by OpenEO back-ends with a file-based data organization. Higher level data-cube oriented back-offices in general do not keep track of the scenes and hence will not be able to parallelize operations on scene level. The type is mostly useful for working with lower-level data products, e.g., to perform atmospheric correction or any other operation that needs scene metadata. \n\n\nreduce_time\n\n\nThis type applies a function to a single time series and produces a zero-dimensional output (scalar or tuple). Notice that the \nview\n parameter for OpenEO processes affects the resolution and window of the time series provided as input to UDFs of this type. \n\n\nreduce_space\n\n\nThis type applies a function to a temporal snapshot of the data and produces a single value or multiband tuple per snapshot. The result is a time series. \n\n\nwindow_time\n\n\nThe provided UDF is called for each pixel and will receive values from pixels within a temporal neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values. \n\n\nwindow_space\n\n\nThe provided UDF is called for each pixel and will receive values from pixels within a spatial neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values. \n\n\nwindow_spacetime\n\n\nSimilar to \nwindow_time\n and \nwindow_space\n, this type derives a new value for the central pixel of a spatiotemporal window of specified size. The provided function receives a (multispectral) spacetime array as input and produces a single value (either scalar or multispectral) as output. The result has the same number of pixels as the input dataset. Windows at boundary regions should be filled with NA values. \n\n\naggregate_time\n\n\nSimilar to \nreduce_time\n this type applies the given UDF independently on pixel time series of the input data but produces a new time series with different temporal resolution. \nreduce_time\n can be seen as a special case of \naggregate_time\n where the temporal dimension is dropped.\nExamples of this UDF type include the generation of monthly aggregates from 16 day data.  The result has the same spatial resolution.\n\n\naggregate_space\n\n\nSimilar to \naggregate_time\n, this type applies the provided function on temporal snapshots of the data and generates an image with different spatial resolution. The result will have the same temporal resolution.\n\n\nchunkreduce_time\n\n\nPartitions the input data into equally sized temporal chunks and aggregates them to a single value or tuple. The function must return a single scalar or tuple (multiband) output. The result has the same spatial but a coarser temporal resolution.\n\n\nchunkreduce_space\n\n\nSimilar to \nchunkreduce_time\n, this type applies the provided function on spatial chunks of the data and generates an aggregated value or tuple. to aggregate. The result will have the same temporal but a coarser spatial resolution. Examples of this type include the generation of image pyramids.\n\n\nchunkreduce_spacetime\n\n\nSimilar to \nchunkreduce_space\n and \nchunkreduce_time\n, UDFs of this type receive spatiotemporal chunks such that the output has lower spatial and lower temporal resolution.\n\n\nR implementation\n\n\n\n\n\n\n\n\nUDF Type\n\n\nFunction prototype\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\napply_pixel\n\n\n\n\n\n\n\n\n\n\napply_scene\n\n\n\n\n\n\n\n\n\n\nreduce_time\n\n\n\n\n\n\n\n\n\n\nreduce_space\n\n\n\n\n\n\n\n\n\n\nwindow_time\n\n\n\n\n\n\n\n\n\n\nwindow_space\n\n\n\n\n\n\n\n\n\n\nwindow_spacetime\n\n\n\n\n\n\n\n\n\n\naggregate_time\n\n\n\n\n\n\n\n\n\n\naggregate_space\n\n\n\n\n\n\n\n\n\n\naggregate_spacetime\n\n\n\n\n\n\n\n\n\n\nchunkreduce_time\n\n\n\n\n\n\n\n\n\n\nchunkreduce_space\n\n\n\n\n\n\n\n\n\n\nchunkreduce_spacetime",
            "title": "UDFs"
        },
        {
            "location": "/udfs/index.html#udfs",
            "text": "User-defined functions (UDFs) can be exposed to the data in different ways. This includes which parts of the\ndata are passed to the function, how the function execution is parallelized, and how the expected output is structured. The OpenEO core API defines the following UDF types:   apply_pixel  apply_scene  reduce_time  reduce_space  window_time  window_space  window_spacetime  aggregate_time  aggregate_space  aggregate_spacetime  chunkreduce_time  chunkreduce_space  chunkreduce_spacetime   This document describes some details of the abovementioned UDF types. Back-ends allowing the execution of UDF's will report, which types they support. For example applying UDFs on individual scenes is not possible on higher level data cube back-ends. In the descriptions below, the question in which format data is streamed to and from the functions is not yet covered. Furthermore, the described categories only include unary operations that take one image (collection) as input.    UDF types  apply_pixel  This type applies a simple function to one pixel of the input image or image collection. The function gets the value of one pixel (including all bands) as input and produces a single scalar or tuple output. The result has the same schema as the input image (collection) but different bands. Examples include the computation of vegetation indexes or filtering cloudy pixels.   apply_scene  This low-level UDF type applies a function on individual scenes.  The function gets a single scene as input and produces a modified \"scene\" with the same spatial footprint. This UDF type will only be supported by OpenEO back-ends with a file-based data organization. Higher level data-cube oriented back-offices in general do not keep track of the scenes and hence will not be able to parallelize operations on scene level. The type is mostly useful for working with lower-level data products, e.g., to perform atmospheric correction or any other operation that needs scene metadata.   reduce_time  This type applies a function to a single time series and produces a zero-dimensional output (scalar or tuple). Notice that the  view  parameter for OpenEO processes affects the resolution and window of the time series provided as input to UDFs of this type.   reduce_space  This type applies a function to a temporal snapshot of the data and produces a single value or multiband tuple per snapshot. The result is a time series.   window_time  The provided UDF is called for each pixel and will receive values from pixels within a temporal neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values.   window_space  The provided UDF is called for each pixel and will receive values from pixels within a spatial neighborhood of specified size around that pixel. Neighboring values can be used to derive a new value of the center pixel, which can be a single scalar value or a (multiband) tuple. Windows at boundary regions should be filled with NA values.   window_spacetime  Similar to  window_time  and  window_space , this type derives a new value for the central pixel of a spatiotemporal window of specified size. The provided function receives a (multispectral) spacetime array as input and produces a single value (either scalar or multispectral) as output. The result has the same number of pixels as the input dataset. Windows at boundary regions should be filled with NA values.   aggregate_time  Similar to  reduce_time  this type applies the given UDF independently on pixel time series of the input data but produces a new time series with different temporal resolution.  reduce_time  can be seen as a special case of  aggregate_time  where the temporal dimension is dropped.\nExamples of this UDF type include the generation of monthly aggregates from 16 day data.  The result has the same spatial resolution.  aggregate_space  Similar to  aggregate_time , this type applies the provided function on temporal snapshots of the data and generates an image with different spatial resolution. The result will have the same temporal resolution.  chunkreduce_time  Partitions the input data into equally sized temporal chunks and aggregates them to a single value or tuple. The function must return a single scalar or tuple (multiband) output. The result has the same spatial but a coarser temporal resolution.  chunkreduce_space  Similar to  chunkreduce_time , this type applies the provided function on spatial chunks of the data and generates an aggregated value or tuple. to aggregate. The result will have the same temporal but a coarser spatial resolution. Examples of this type include the generation of image pyramids.  chunkreduce_spacetime  Similar to  chunkreduce_space  and  chunkreduce_time , UDFs of this type receive spatiotemporal chunks such that the output has lower spatial and lower temporal resolution.  R implementation     UDF Type  Function prototype  Details      apply_pixel      apply_scene      reduce_time      reduce_space      window_time      window_space      window_spacetime      aggregate_time      aggregate_space      aggregate_spacetime      chunkreduce_time      chunkreduce_space      chunkreduce_spacetime",
            "title": "UDFs"
        },
        {
            "location": "/views/index.html",
            "text": "Data Views\n\n\nThe OpenEO API supports to look at datasets from different \nviews\n. Views describe at which resolution and for which spatial and temporal extent the original Earth observation data are processed and hence can be used to run processes interactively on small parts of the original data without need to wait for long-running processes. The idea is similar to what Google Earth Engine does by reducing computations only to pixels that are actually displayed.\n\n\nExample\n\n\nThe following JSON object describes a coarse resolution (0.25\u00b0 x 0.25\u00b0) view of monthly aggregated data. \n\n\n\"view\": {\n    \"space\": {\n      \"srs\": \"EPSG:4326\",\n      \"window\": {\n        \"left\": -10.21,\n        \"top\": 53.23,\n        \"right\": 12.542,\n        \"bottom\": 12.32\n      },\n      \"cell_size\": 0.25,\n      \"resampling\": \"nearest\"\n    },\n    \"time\": {\n      \"window\": {\n        \"start\": \"2017-01-01\",\n        \"end\": \"2018-01-01\"\n      },\n      \"time_step\": \"P1M\",\n      \"resampling\": \"nearest\"\n    }\n  }",
            "title": "Data Views"
        },
        {
            "location": "/views/index.html#data-views",
            "text": "The OpenEO API supports to look at datasets from different  views . Views describe at which resolution and for which spatial and temporal extent the original Earth observation data are processed and hence can be used to run processes interactively on small parts of the original data without need to wait for long-running processes. The idea is similar to what Google Earth Engine does by reducing computations only to pixels that are actually displayed.",
            "title": "Data Views"
        },
        {
            "location": "/views/index.html#example",
            "text": "The following JSON object describes a coarse resolution (0.25\u00b0 x 0.25\u00b0) view of monthly aggregated data.   \"view\": {\n    \"space\": {\n      \"srs\": \"EPSG:4326\",\n      \"window\": {\n        \"left\": -10.21,\n        \"top\": 53.23,\n        \"right\": 12.542,\n        \"bottom\": 12.32\n      },\n      \"cell_size\": 0.25,\n      \"resampling\": \"nearest\"\n    },\n    \"time\": {\n      \"window\": {\n        \"start\": \"2017-01-01\",\n        \"end\": \"2018-01-01\"\n      },\n      \"time_step\": \"P1M\",\n      \"resampling\": \"nearest\"\n    }\n  }",
            "title": "Example"
        },
        {
            "location": "/poc/index.html",
            "text": "Proof of Concept\n\n\nThis page gives a detailed description of the OpenEO proof of concept and gives a list and specification of what needs to be implemented. The proof of concept will consist of\n\n\n\n\nat least three clearly defined example processes (see below),\n\n\na prototypical API specification including communication API call sequences of the processes (see below),\n\n\nimplementations of the processes on three back-ends (file-based, Spark, EURAC), and\n\n\nprototypical clients in R and Python.\n\n\n\n\nBelow, we define the examples processes and how they are translated to sequences of API calls.\n\n\nExample Process 1: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery\n\n\n1. Check whether Sentinel 2A Level 1C data is available at the back-end\n\n\nRequest\n\n\nGET /data/Sentinel2A-L1C\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel-2A-L1C\",\n    \"description\": \"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": \n    [{\n        \"band_id\": \"1\",\n        \"wavelength_nm\": 443.9,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"2\",\n        \"name\": \"blue\",\n        \"wavelength_nm\": 496.6,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"3\",\n        \"name\": \"green\",\n        \"wavelength_nm\": 560,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"4\",\n        \"name\": \"red\",\n        \"wavelength_nm\": 664.5,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"5\",\n        \"wavelength_nm\": 703.9,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"6\",\n        \"wavelength_nm\": 740.2,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"7\",\n        \"wavelength_nm\": 782.5,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8\",\n        \"name\": \"nir\",\n        \"wavelength_nm\": 835.1,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8a\",\n        \"wavelength_nm\": 864.8,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"9\",\n        \"wavelength_nm\": 945,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"10\",\n        \"wavelength_nm\": 1373.5,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"11\",\n        \"wavelength_nm\": 1613.7,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"12\",\n        \"wavelength_nm\": 2202.4,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    }]\n}\n\n\n\n\n\n2. Check that needed processes are available\n\n\nRequest\n\n\nGET /processes/filter_bbox\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"process_id\": \"filter_bbox\",\n    \"description\": \"Drops observations from a collection that are located outside of a given bounding box.\",\n    \"args\": {\n       \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"left\" : {\n            \"description\" : \"left boundary (longitude / easting)\"\n        },\n        \"right\" : {\n            \"description\" : \"right boundary (longitude / easting)\"\n        },\n        \"top\" : {\n            \"description\" : \"top boundary (latitude / northing)\"\n        },\n        \"bottom\" : {\n            \"description\" : \"bottom boundary (latitude / northing)\"\n        },\n        \"srs\" : {\n            \"description\" : \"spatial reference system of boundaries as proj4 or EPSG:12345 like string\"\n        }\n    }\n}\n\n\n\n\nRequest\n\n\nGET /processes/filter_daterange\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"process_id\": \"filter_daterange\",\n    \"description\": \"Drops observations from a collection that have been captured before a start or after a given end date.\",\n    \"args\": {\n        \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"from\" : {\n            \"description\" : \"start date\"\n        },\n        \"to\" : {\n            \"description\" : \"end date\"\n        }\n    }\n}\n\n\n\n\nRequest\n\n\nGET /processes/NDVI\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"process_id\": \"NDVI\",\n    \"description\": \"Finds the minimum value of time series for all bands of the input dataset.\",\n    \"args\": {\n        \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"red\" : {\n            \"description\" : \"reference to the red band\"\n        },\n        \"nir\" : {\n            \"description\" : \"reference to the nir band\"\n        }\n    }\n}\n\n\n\n\nRequest\n\n\nGET /processes/min_time\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"process_id\": \"min_time\",\n    \"description\": \"Finds the minimum value of time series for all bands of the input dataset.\",\n    \"args\": {\n       \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n    }\n}\n\n\n\n\n3. Create a job with the computation at the back-end\n\n\nRequest\n\n\nPOST /jobs&evaluate=lazy\nBody:\n{\n  \"process_graph\": {\n    \"process_id\": \"min_time\",\n    \"args\": {\n      \"collections\": [{\n        \"process_id\": \"NDVI\",\n        \"args\": {\n          \"collections\": [{\n            \"process_id\": \"filter_daterange\",\n            \"args\": {\n              \"collections\": [{\n                \"process_id\": \"filter_bbox\",\n                \"args\": {\n                \"collections\": [{\n                    \"product_id\": \"S2_L2A_T32TPS_20M\"\n                }],\n                \"left\" : 652000,\n                \"right\" :672000,\n                \"top\" : 5161000,\n                \"bottom\" : 5181000,\n                \"srs\" : \"EPSG:32632\"\n                }\n              }],\n          \"from\": \"2017-01-01\",\n              \"to\": \"2017-01-31\"\n            }\n          }],\n          \"red\": \"B04\",\n          \"nir\": \"B8A\"\n        }\n      }]\n    }\n  }\n}\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\"job_id\" : \"2a8ffb20c2b235a3f3e3351f\"}\n\n\n\n\n4. Download the data on demand with WCS\n\n\nRequest\n\n\nGET /download/2a8ffb20c2b235a3f3e3351f/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCapabilities\n\n\n\n\nResponse\n\n\nomitted\n\n\nRequest\n\n\nGET /download/2a8ffb20c2b235a3f3e3351f/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCoverage&COVERAGEID=2a8ffb20c2b235a3f3e3351f&FORMAT=image/tiff&SUBSET=x,http://www.opengis.net/def/crs/EPSG/0/4326(16.1,16.5)&SUBSET=y,http://www.opengis.net/def/crs/EPSG/0/4326(47.9,48.6)&&SIZE=x(200)&SIZE=y(200)\n\n\n\n\nResponse\n \n\nomitted\n\n\n5. Stop the job\n\n\nRequest\n\n\nGET /jobs/2a8ffb20c2b235a3f3e3351f/cancel\n\n\n\n\nResponse\n\n\nHTTP 200/OK\n\n\n\n\nExample Process 2: Create a monthly aggregated Sentinel 1 product from a custom Python script\n\n\n1. Ask the back-end for available Sentinel 1 data\n\n\nRequest\n\n\nGET /data/Sentinel1-L1-IW-GRD\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel1-L1-IW-GRD\",\n    \"description\": \"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": [\n    {\n        \"band_id\": \"VV\",\n    },\n    {\n        \"band_id\": \"VH\",\n    }\n    ]\n}\n\n\n\n\n2. Ask the back-end whether it supports Python UDFs of type aggregate_time and get details about expected parameters\n\n\nRequest\n\n\nGET /udf\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n  \"Python\": {\n    \"udf_types\": [\n      \"reduce_time\",\n      \"aggregate_time\",\n      \"apply_pixel\",\n      \"\n    ],\n    \"versions\": {\n      \"3.6.3\": {\n        \"packages\": [\n          \"numpy\",\n          \"scipy\",\n          \"pandas\",\n          \"matplotlib\",\n          \"ipython\",\n          \"jupyter\",\n          \"GDAL\"\n        ]\n      }\n    }\n  }\n}\n\n\n\n\nRequest\n\n\nGET /udf/Python/aggregate_time\n\n\n\n\nResponse\n\n\nHTTP 200/OK\n{\n  \"process_id\": \"/udf/Python/aggregate_time\",\n  \"description\": \"Runs a Python script for each time series of the input dataset.\",\n  \"args\": {\n    \"collections\": {\n      \"description\": \"array of input collections with one element\"\n    },\n    \"script\": {\n      \"description\": \"Python script that will be executed over all time series, gets time series as (Pandas) DataFrame and expects a new DataFrame as output.\"\n    },\n    \"version\" : {\n       \"description\" : \"Python version to use, defaults to the latest available version.\"\n       \"required\" : false,\n       \"default\" : \"latest\" \n    }\n  }\n}\n\n\n\n\n3. Upload python script\n\n\nRequest\n\n\nPUT /users/me/files/s1_aggregate.py\n\n\n\n\nResponse\n\n\nHTTP 200/OK\n\n\n\n\n4. Create a job\n\n\nRequest\n\n\nPOST /jobs?evaluate=lazy\nBody:\n{\n    \"process_graph\": {\n        \"process_id\": \"/udf/Python/aggregate_time\",\n        \"args\": {\n            \"script\" : \"/users/me/files/s1_aggregate.py\",        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"product_id\": \"Sentinel1-L1-IW-GRD\"\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }\n            }]\n        }\n    }\n}\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\"job_id\" : \"3723c32fb7b24698832ca71f2d3f18aa\"}\n\n\n\n\n5. Download results as TMS\n\n\nExample Request\n\n\nGET /download/3723c32fb7b24698832ca71f2d3f18aa/tms/2017-01-01/12/2232/2668/?bands=1\n\n\n\n\nResponse\n\n\nomitted\n\n\nExample Process 3: Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons\n\n\n1. Check whether Sentinel 2A Level 1C data is available at the back-end\n\n\nRequest\n\n\nGET /data/Sentinel2A-L1C\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel-2A-L1C\",\n    \"description\": \"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": \n    [{\n        \"band_id\": \"1\",\n        \"wavelength_nm\": 443.9,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"2\",\n        \"name\": \"blue\",\n        \"wavelength_nm\": 496.6,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"3\",\n        \"name\": \"green\",\n        \"wavelength_nm\": 560,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"4\",\n        \"name\": \"red\",\n        \"wavelength_nm\": 664.5,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"5\",\n        \"wavelength_nm\": 703.9,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"6\",\n        \"wavelength_nm\": 740.2,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"7\",\n        \"wavelength_nm\": 782.5,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8\",\n        \"name\": \"nir\",\n        \"wavelength_nm\": 835.1,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8a\",\n        \"wavelength_nm\": 864.8,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"9\",\n        \"wavelength_nm\": 945,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"10\",\n        \"wavelength_nm\": 1373.5,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"11\",\n        \"wavelength_nm\": 1613.7,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"12\",\n        \"wavelength_nm\": 2202.4,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    }]\n}\n\n\n\n\n2. Check whether the back-end supports computing \nzonal_statistics\n\n\nRequest\n\n\nGET /processes/zonal_statistics\n\n\n\n\nResponse\n\n\nHTTP 200/OK\n{\n  \"process_id\": \"zonal_statistics\",\n  \"description\": \"Runs a Python script for each time series of the input dataset.\",\n  \"args\": {\n    \"collections\": {\n      \"description\": \"array of input collections with one element\"\n    },\n    \"regions\": {\n      \"description\": \"Polygon file readable by OGR\"\n    },\n    \"func\" : {\n       \"description\" : \"Function to apply over the polygons, one of `\"avg\"`, `\"min\"`, `\"max\"`, `\"median\"`, `\"q25\"`, or `\"q75\"` .\", \n       \"required\" : false,\n       \"default\" : \"avg\" \n    },\n    \"outformat\" : {\n       \"description\" : \"Output format as OGR identifier string, defaults to GeoPackage\", \n       \"required\" : false,\n       \"default\" : \"GPKG\" \n    }\n  }\n}\n\n\n\n\n3. Upload a GeoJSON Polygon\n\n\nRequest\n\n\nPUT /user/me/files/polygon1.json\n\n\n\n\nResponse\n\n\nHTTP 200/OK\n\n\n\n\n4. Create a job with the computation at the back-end\n\n\nRequest\n\n\nPOST /jobs?evaluate=batch\nBody:\n{\n    \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n}\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\"job_id\" : \"f6ea12c5e283438a921b525af826da08\"}\n\n\n\n\n5. Check job status\n\n\nRequest\n\n\nGET /jobs/f6ea12c5e283438a921b525af826da08\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n  \"job_id\": \"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\": \"bd6f9faf93b4\",\n  \"status\": \"running\",\n  \"task\": {\n    \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n  },\n  \"submitted\": \"2017-01-01 09:32:12\",\n  \"last_update\": \"2017-01-01 09:36:18\",\n  \"consumed_credits\": \"0.231\"\n}\n\n\n\n\nRequest\n\n\nGET /jobs/f6ea12c5e283438a921b525af826da08\n\n\n\n\nResponse\n\n\nHTTP 200/OK\nBody:\n{\n  \"job_id\": \"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\": \"bd6f9faf93b4\",\n  \"status\": \"finished\",\n  \"task\": {\n   \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n  },\n  \"submitted\": \"2017-01-01 09:32:12\",\n  \"last_update\": \"2017-01-01 09:36:57\",\n  \"consumed_credits\": \"0.231\"\n}\n\n\n\n\n7. Download results\n\n\nExample Request\n\n\nGET /download/f6ea12c5e283438a921b525af826da08\n\n\n\n\nResponse (GPKG file)\n\n\nomitted",
            "title": "Proof of Concept"
        },
        {
            "location": "/poc/index.html#proof-of-concept",
            "text": "This page gives a detailed description of the OpenEO proof of concept and gives a list and specification of what needs to be implemented. The proof of concept will consist of   at least three clearly defined example processes (see below),  a prototypical API specification including communication API call sequences of the processes (see below),  implementations of the processes on three back-ends (file-based, Spark, EURAC), and  prototypical clients in R and Python.   Below, we define the examples processes and how they are translated to sequences of API calls.",
            "title": "Proof of Concept"
        },
        {
            "location": "/poc/index.html#example-process-1-deriving-minimum-ndvi-measurements-over-pixel-time-series-of-sentinel-2-imagery",
            "text": "1. Check whether Sentinel 2A Level 1C data is available at the back-end  Request  GET /data/Sentinel2A-L1C  Response  HTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel-2A-L1C\",\n    \"description\": \"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": \n    [{\n        \"band_id\": \"1\",\n        \"wavelength_nm\": 443.9,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"2\",\n        \"name\": \"blue\",\n        \"wavelength_nm\": 496.6,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"3\",\n        \"name\": \"green\",\n        \"wavelength_nm\": 560,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"4\",\n        \"name\": \"red\",\n        \"wavelength_nm\": 664.5,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"5\",\n        \"wavelength_nm\": 703.9,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"6\",\n        \"wavelength_nm\": 740.2,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"7\",\n        \"wavelength_nm\": 782.5,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8\",\n        \"name\": \"nir\",\n        \"wavelength_nm\": 835.1,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8a\",\n        \"wavelength_nm\": 864.8,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"9\",\n        \"wavelength_nm\": 945,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"10\",\n        \"wavelength_nm\": 1373.5,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"11\",\n        \"wavelength_nm\": 1613.7,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"12\",\n        \"wavelength_nm\": 2202.4,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    }]\n}  2. Check that needed processes are available  Request  GET /processes/filter_bbox  Response  HTTP 200/OK\nBody:\n{\n    \"process_id\": \"filter_bbox\",\n    \"description\": \"Drops observations from a collection that are located outside of a given bounding box.\",\n    \"args\": {\n       \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"left\" : {\n            \"description\" : \"left boundary (longitude / easting)\"\n        },\n        \"right\" : {\n            \"description\" : \"right boundary (longitude / easting)\"\n        },\n        \"top\" : {\n            \"description\" : \"top boundary (latitude / northing)\"\n        },\n        \"bottom\" : {\n            \"description\" : \"bottom boundary (latitude / northing)\"\n        },\n        \"srs\" : {\n            \"description\" : \"spatial reference system of boundaries as proj4 or EPSG:12345 like string\"\n        }\n    }\n}  Request  GET /processes/filter_daterange  Response  HTTP 200/OK\nBody:\n{\n    \"process_id\": \"filter_daterange\",\n    \"description\": \"Drops observations from a collection that have been captured before a start or after a given end date.\",\n    \"args\": {\n        \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"from\" : {\n            \"description\" : \"start date\"\n        },\n        \"to\" : {\n            \"description\" : \"end date\"\n        }\n    }\n}  Request  GET /processes/NDVI  Response  HTTP 200/OK\nBody:\n{\n    \"process_id\": \"NDVI\",\n    \"description\": \"Finds the minimum value of time series for all bands of the input dataset.\",\n    \"args\": {\n        \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n        \"red\" : {\n            \"description\" : \"reference to the red band\"\n        },\n        \"nir\" : {\n            \"description\" : \"reference to the nir band\"\n        }\n    }\n}  Request  GET /processes/min_time  Response  HTTP 200/OK\nBody:\n{\n    \"process_id\": \"min_time\",\n    \"description\": \"Finds the minimum value of time series for all bands of the input dataset.\",\n    \"args\": {\n       \"collections\": {\n            \"description\": \"array of input collections with one element\"\n        },\n    }\n}  3. Create a job with the computation at the back-end  Request  POST /jobs&evaluate=lazy\nBody:\n{\n  \"process_graph\": {\n    \"process_id\": \"min_time\",\n    \"args\": {\n      \"collections\": [{\n        \"process_id\": \"NDVI\",\n        \"args\": {\n          \"collections\": [{\n            \"process_id\": \"filter_daterange\",\n            \"args\": {\n              \"collections\": [{\n                \"process_id\": \"filter_bbox\",\n                \"args\": {\n                \"collections\": [{\n                    \"product_id\": \"S2_L2A_T32TPS_20M\"\n                }],\n                \"left\" : 652000,\n                \"right\" :672000,\n                \"top\" : 5161000,\n                \"bottom\" : 5181000,\n                \"srs\" : \"EPSG:32632\"\n                }\n              }],\n          \"from\": \"2017-01-01\",\n              \"to\": \"2017-01-31\"\n            }\n          }],\n          \"red\": \"B04\",\n          \"nir\": \"B8A\"\n        }\n      }]\n    }\n  }\n}  Response  HTTP 200/OK\nBody:\n{\"job_id\" : \"2a8ffb20c2b235a3f3e3351f\"}  4. Download the data on demand with WCS  Request  GET /download/2a8ffb20c2b235a3f3e3351f/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCapabilities  Response  omitted  Request  GET /download/2a8ffb20c2b235a3f3e3351f/wcs?SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCoverage&COVERAGEID=2a8ffb20c2b235a3f3e3351f&FORMAT=image/tiff&SUBSET=x,http://www.opengis.net/def/crs/EPSG/0/4326(16.1,16.5)&SUBSET=y,http://www.opengis.net/def/crs/EPSG/0/4326(47.9,48.6)&&SIZE=x(200)&SIZE=y(200)  Response   omitted  5. Stop the job  Request  GET /jobs/2a8ffb20c2b235a3f3e3351f/cancel  Response  HTTP 200/OK",
            "title": "Example Process 1: Deriving minimum NDVI measurements over pixel time series of Sentinel 2 imagery"
        },
        {
            "location": "/poc/index.html#example-process-2-create-a-monthly-aggregated-sentinel-1-product-from-a-custom-python-script",
            "text": "1. Ask the back-end for available Sentinel 1 data  Request  GET /data/Sentinel1-L1-IW-GRD  Response  HTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel1-L1-IW-GRD\",\n    \"description\": \"Sentinel 1 C-band Synthetic Aperture Radar (SAR) Ground Range Data\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": [\n    {\n        \"band_id\": \"VV\",\n    },\n    {\n        \"band_id\": \"VH\",\n    }\n    ]\n}  2. Ask the back-end whether it supports Python UDFs of type aggregate_time and get details about expected parameters  Request  GET /udf  Response  HTTP 200/OK\nBody:\n{\n  \"Python\": {\n    \"udf_types\": [\n      \"reduce_time\",\n      \"aggregate_time\",\n      \"apply_pixel\",\n      \"\n    ],\n    \"versions\": {\n      \"3.6.3\": {\n        \"packages\": [\n          \"numpy\",\n          \"scipy\",\n          \"pandas\",\n          \"matplotlib\",\n          \"ipython\",\n          \"jupyter\",\n          \"GDAL\"\n        ]\n      }\n    }\n  }\n}  Request  GET /udf/Python/aggregate_time  Response  HTTP 200/OK\n{\n  \"process_id\": \"/udf/Python/aggregate_time\",\n  \"description\": \"Runs a Python script for each time series of the input dataset.\",\n  \"args\": {\n    \"collections\": {\n      \"description\": \"array of input collections with one element\"\n    },\n    \"script\": {\n      \"description\": \"Python script that will be executed over all time series, gets time series as (Pandas) DataFrame and expects a new DataFrame as output.\"\n    },\n    \"version\" : {\n       \"description\" : \"Python version to use, defaults to the latest available version.\"\n       \"required\" : false,\n       \"default\" : \"latest\" \n    }\n  }\n}  3. Upload python script  Request  PUT /users/me/files/s1_aggregate.py  Response  HTTP 200/OK  4. Create a job  Request  POST /jobs?evaluate=lazy\nBody:\n{\n    \"process_graph\": {\n        \"process_id\": \"/udf/Python/aggregate_time\",\n        \"args\": {\n            \"script\" : \"/users/me/files/s1_aggregate.py\",        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"product_id\": \"Sentinel1-L1-IW-GRD\"\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }\n            }]\n        }\n    }\n}  Response  HTTP 200/OK\nBody:\n{\"job_id\" : \"3723c32fb7b24698832ca71f2d3f18aa\"}  5. Download results as TMS  Example Request  GET /download/3723c32fb7b24698832ca71f2d3f18aa/tms/2017-01-01/12/2232/2668/?bands=1  Response  omitted",
            "title": "Example Process 2: Create a monthly aggregated Sentinel 1 product from a custom Python script"
        },
        {
            "location": "/poc/index.html#example-process-3-compute-time-series-of-zonal-regional-statistics-of-sentinel-2-imagery-over-user-uploaded-polygons",
            "text": "1. Check whether Sentinel 2A Level 1C data is available at the back-end  Request  GET /data/Sentinel2A-L1C  Response  HTTP 200/OK\nBody:\n{\n    \"product_id\": \"Sentinel-2A-L1C\",\n    \"description\": \"Sentinel 2 Level-1C: Top-of-atmosphere reflectances in cartographic geometry\",\n    \"source\": \"European Space Agency (ESA)\",\n    \"extent\": [ -34, 35, 39, 71],\n    \"time\": [ \"2016-01-01\", \"2017-10-01\"],\n    \"bands\": \n    [{\n        \"band_id\": \"1\",\n        \"wavelength_nm\": 443.9,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"2\",\n        \"name\": \"blue\",\n        \"wavelength_nm\": 496.6,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"3\",\n        \"name\": \"green\",\n        \"wavelength_nm\": 560,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"4\",\n        \"name\": \"red\",\n        \"wavelength_nm\": 664.5,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"5\",\n        \"wavelength_nm\": 703.9,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"6\",\n        \"wavelength_nm\": 740.2,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"7\",\n        \"wavelength_nm\": 782.5,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8\",\n        \"name\": \"nir\",\n        \"wavelength_nm\": 835.1,\n        \"res_m\": 10,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"8a\",\n        \"wavelength_nm\": 864.8,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"9\",\n        \"wavelength_nm\": 945,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"10\",\n        \"wavelength_nm\": 1373.5,\n        \"res_m\": 60,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"11\",\n        \"wavelength_nm\": 1613.7,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    },\n    {\n        \"band_id\": \"12\",\n        \"wavelength_nm\": 2202.4,\n        \"res_m\": 20,\n        \"scale\": 0.0001,\n        \"offset\": 0,\n        \"type\": \"int16\",\n        \"unit\": \"1\"\n    }]\n}  2. Check whether the back-end supports computing  zonal_statistics  Request  GET /processes/zonal_statistics  Response  HTTP 200/OK\n{\n  \"process_id\": \"zonal_statistics\",\n  \"description\": \"Runs a Python script for each time series of the input dataset.\",\n  \"args\": {\n    \"collections\": {\n      \"description\": \"array of input collections with one element\"\n    },\n    \"regions\": {\n      \"description\": \"Polygon file readable by OGR\"\n    },\n    \"func\" : {\n       \"description\" : \"Function to apply over the polygons, one of `\"avg\"`, `\"min\"`, `\"max\"`, `\"median\"`, `\"q25\"`, or `\"q75\"` .\", \n       \"required\" : false,\n       \"default\" : \"avg\" \n    },\n    \"outformat\" : {\n       \"description\" : \"Output format as OGR identifier string, defaults to GeoPackage\", \n       \"required\" : false,\n       \"default\" : \"GPKG\" \n    }\n  }\n}  3. Upload a GeoJSON Polygon  Request  PUT /user/me/files/polygon1.json  Response  HTTP 200/OK  4. Create a job with the computation at the back-end  Request  POST /jobs?evaluate=batch\nBody:\n{\n    \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n}  Response  HTTP 200/OK\nBody:\n{\"job_id\" : \"f6ea12c5e283438a921b525af826da08\"}  5. Check job status  Request  GET /jobs/f6ea12c5e283438a921b525af826da08  Response  HTTP 200/OK\nBody:\n{\n  \"job_id\": \"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\": \"bd6f9faf93b4\",\n  \"status\": \"running\",\n  \"task\": {\n    \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n  },\n  \"submitted\": \"2017-01-01 09:32:12\",\n  \"last_update\": \"2017-01-01 09:36:18\",\n  \"consumed_credits\": \"0.231\"\n}  Request  GET /jobs/f6ea12c5e283438a921b525af826da08  Response  HTTP 200/OK\nBody:\n{\n  \"job_id\": \"f6ea12c5e283438a921b525af826da08\",\n  \"user_id\": \"bd6f9faf93b4\",\n  \"status\": \"finished\",\n  \"task\": {\n   \"process_graph\": {\n        \"process_id\": \"zonal_statistics\",\n        \"args\": {        \n            \"collections\": [{\n                \"process_id\": \"filter_daterange\",\n                \"args\": {\n                    \"collections\": [{\n                        \"process_id\": \"filter_bbox\",\n                        \"args\": {\n                            \"collections\": [{\n                                \"process_id\" : \"filter_bands\",\n                                \"args\" : {\n                                    \"collections\" : [\n                                        {\n                                            \"product_id\": \"Sentinel2-L1C\"\n                                        }\n                                    ],\n                                    \"bands\": 8\n                                }\n                            }],\n                            \"left\" : \u200e 16.1,\n                            \"right\" : \u200e16.6,\n                            \"top\" : 48.6,\n                            \"bottom\" : 47.2,\n                            \"srs\" : \"EPSG:4326\"\n                        },\n                    }],\n                    \"from\": \"2017-01-01\",\n                    \"to\": \"2017-01-31\"\n                }          \n            }],\n            \"regions\" : \"/users/me/files/,\n            \"func\" : \"avg\",\n            \"outformat\" : \"GPKG\"\n        }\n    }\n  },\n  \"submitted\": \"2017-01-01 09:32:12\",\n  \"last_update\": \"2017-01-01 09:36:57\",\n  \"consumed_credits\": \"0.231\"\n}  7. Download results  Example Request  GET /download/f6ea12c5e283438a921b525af826da08  Response (GPKG file)  omitted",
            "title": "Example Process 3: Compute time series of zonal (regional) statistics of Sentinel 2 imagery over user-uploaded polygons"
        },
        {
            "location": "/drivers/index.html",
            "text": "",
            "title": "Driver Features"
        },
        {
            "location": "/apireference/index.html",
            "text": "__this is a placeholder file that will be replaced by generated docs of the OpenAPI spec automatically_",
            "title": "API Reference"
        }
    ]
}